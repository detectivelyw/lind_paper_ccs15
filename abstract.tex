\begin{abstract}

Securing privileged code, such as a kernel or hypervisor, is essential for
computer security.  Despite substantial effort, privileged code 
still contains exploitable vulnerabilities.  This has led to techniques
such as system call filtering, operating system virtualization, and library
OSes to allow secure computation of programs. 
Unfortunately, these techniques also exhibit exploitable vulnerabilities and do not fully
prevent attackers from exploiting flaws in the underlying system.  

In this paper, we analyze the reason that existing techniques cannot
effectively protect system kernel.  Moreover, 
we devise a metric that allows us to predict \yiwen{``predict'' seems a big word to me. I am 
not sure we can predict results with new bugs. Maybe we want to say ``evaluate'' or ``understand''}
which portions of the kernel are less likely to contain vulnerabilities.
This metric is based upon whether lines of code in the kernel get 
executed by popular programs.  Our analysis shows that commonly used kernel 
paths contain fewer vulnerabilities than other less commonly used parts of the kernel.  

This observation has significant implications for how secure systems
should be designed.  We therefore devised a novel ``safely-reimplement'' 
design pattern for secure systems \yanyan{such that it uses common paths, etc}. 
We implemented a prototype security 
system Lind that uses this design pattern
%accesses only commonly used kernel paths, and have a very small trusted computing base 
such that it places limited trust in the privileged code. 
Our experimental results show that programs run in Lind can trigger many
fewer vulnerabilities (X\%) compared to existing systems like VirtualBox (XX\%),
Graphene (XX\%), and Bascule (XX\%).

\end{abstract}
